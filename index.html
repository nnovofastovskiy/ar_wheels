<!doctype html>
<html lang="ru">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>YOLOv11 + WASM — камера / файл / сегментация</title>
  <style>
    body {
      font-family: system-ui, sans-serif;
      background: #0f172a;
      color: #e2e8f0;
      display: flex;
      flex-direction: column;
      align-items: center;
      margin: 0;
      padding: 1rem;
    }
    h1 { margin-bottom: .5rem }

    #viewer {
      position: relative;
      display: inline-block;
      margin-top: .5rem;
    }

    #video, #overlay {
      position: absolute;
      top: 0;
      left: 0;
      width: 640px;
      height: 480px;
      border-radius: 10px;
      box-shadow: 0 8px 24px rgba(0,0,0,0.6);
    }
    #video { z-index: 1; }
    #overlay {
      z-index: 2;
      pointer-events: none;
    }

    #controls {
      margin-top: 10px;
      display: flex;
      gap: 1rem;
      flex-wrap: wrap;
      justify-content: center;
    }

    button, input[type=file] {
      background: #2563eb;
      color: #fff;
      border: none;
      border-radius: 8px;
      padding: .5rem 1rem;
      cursor: pointer;
    }

    #status {
      margin-top: .5rem;
    }
  </style>
</head>
<body>
  <h1>YOLOv11 + WASM — Сегментация (камера или файл)</h1>

  <div id="viewer">
    <video id="video" autoplay playsinline width="640" height="480" style="display:none"></video>
    <canvas id="overlay" width="640" height="480"></canvas>
  </div>

  <div id="controls">
    <button id="startCam">Камера</button>
    <input id="fileInput" type="file" accept="image/*,video/*" />
    <button id="stopBtn" disabled>Остановить</button>
    <button id="downloadBtn" style="display:none">Скачать результат</button>
  </div>

  <div id="status">Загрузка...</div>

  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <script>
  const MODEL_URL = './models/best.onnx';
  const CLASSES_URL = './models/classes.json';
  const MODEL_INPUT = 640;

  const video = document.getElementById('video');
  const overlay = document.getElementById('overlay');
  const ctx = overlay.getContext('2d');
  const startCam = document.getElementById('startCam');
  const fileInput = document.getElementById('fileInput');
  const stopBtn = document.getElementById('stopBtn');
  const downloadBtn = document.getElementById('downloadBtn');
  const statusEl = document.getElementById('status');

  let session = null;
  let stream = null;
  let rafId = null;
  let classes = [];

  function status(t){ statusEl.textContent = t }

  // === Предобработка кадра ===
  function preprocess(source) {
    const tmp = document.createElement('canvas');
    tmp.width = MODEL_INPUT; tmp.height = MODEL_INPUT;
    const tctx = tmp.getContext('2d');
    const vw = source.videoWidth || source.width;
    const vh = source.videoHeight || source.height;
    const scale = Math.min(MODEL_INPUT / vw, MODEL_INPUT / vh);
    const sw = vw * scale, sh = vh * scale;
    const dx = (MODEL_INPUT - sw) / 2, dy = (MODEL_INPUT - sh) / 2;
    tctx.fillStyle = "black";
    tctx.fillRect(0, 0, MODEL_INPUT, MODEL_INPUT);
    tctx.drawImage(source, 0, 0, vw, vh, dx, dy, sw, sh);

    const img = tctx.getImageData(0, 0, MODEL_INPUT, MODEL_INPUT);
    const input = new Float32Array(3 * MODEL_INPUT * MODEL_INPUT);
    for (let i = 0; i < MODEL_INPUT * MODEL_INPUT; i++) {
      input[i] = img.data[i * 4] / 255;
      input[i + MODEL_INPUT * MODEL_INPUT] = img.data[i * 4 + 1] / 255;
      input[i + 2 * MODEL_INPUT * MODEL_INPUT] = img.data[i * 4 + 2] / 255;
    }
    return new ort.Tensor('float32', input, [1, 3, MODEL_INPUT, MODEL_INPUT]);
  }

  function sigmoid(x){ return 1 / (1 + Math.exp(-x)); }
  function iou(a,b){
    const x1=Math.max(a.x1,b.x1),y1=Math.max(a.y1,b.y1),
          x2=Math.min(a.x2,b.x2),y2=Math.min(a.y2,b.y2);
    const w=Math.max(0,x2-x1),h=Math.max(0,y2-y1);
    const inter=w*h,areaA=(a.x2-a.x1)*(a.y2-a.y1),areaB=(b.x2-b.x1)*(b.y2-b.y1);
    return inter/(areaA+areaB-inter+1e-6);
  }
  function nms(boxes,scores,t=0.45){
    const idxs=scores.map((s,i)=>({s,i})).sort((a,b)=>b.s-a.s).map(x=>x.i);
    const keep=[];
    while(idxs.length){
      const i=idxs.shift();
      keep.push(i);
      for(let j=idxs.length-1;j>=0;j--){
        if(iou(boxes[i],boxes[idxs[j]])>t) idxs.splice(j,1);
      }
    }
    return keep;
  }

  function buildMask(proto, coeffs, mask_h, mask_w) {
    const mask = new Float32Array(mask_h * mask_w);
    for (let i=0; i<coeffs.length; i++){
      const ch=proto.slice(i*mask_h*mask_w, (i+1)*mask_h*mask_w);
      for(let j=0;j<mask.length;j++) mask[j]+=ch[j]*coeffs[i];
    }
    for(let i=0;i<mask.length;i++) mask[i]=sigmoid(mask[i]);
    return mask;
  }

  function drawMask(mask, mask_h, mask_w, box, color){
    const img=ctx.createImageData(mask_w,mask_h);
    for(let i=0;i<mask.length;i++){
      const v=mask[i]>0.5?255:0;
      img.data[i*4]=color[0];
      img.data[i*4+1]=color[1];
      img.data[i*4+2]=color[2];
      img.data[i*4+3]=v;
    }
    const m=document.createElement('canvas');
    m.width=mask_w; m.height=mask_h;
    const mctx=m.getContext('2d');
    mctx.putImageData(img,0,0);
    ctx.globalAlpha=0.4;
    ctx.drawImage(m,box.x1,box.y1,box.x2-box.x1,box.y2-box.y1);
    ctx.globalAlpha=1;
  }

  async function runInference(source){
    const tensor=preprocess(source);
    const feeds={[session.inputNames[0]]:tensor};
    const out=await session.run(feeds);
    const detOut=out[session.outputNames[0]];
    const protoOut=out[session.outputNames[1]];
    const data=detOut.data;
    const [_,num,dim]=detOut.dims;
    const mask_dim=protoOut.dims[1],mask_h=protoOut.dims[2],mask_w=protoOut.dims[3];
    const boxes=[],scores=[],clsIdx=[],coeffsAll=[];
    for(let i=0;i<num;i++){
      const off=i*dim;
      const cx=data[off],cy=data[off+1],w=data[off+2],h=data[off+3];
      const conf=data[off+4];
      let best=-1,score=0;
      for(let c=5;c<dim-mask_dim;c++){
        if(data[off+c]>score){score=data[off+c];best=c-5;}
      }
      const final=conf*score;
      if(final<0.4) continue;
      boxes.push({x1:(cx-w/2)*overlay.width,y1:(cy-h/2)*overlay.height,
                  x2:(cx+w/2)*overlay.width,y2:(cy+h/2)*overlay.height});
      scores.push(final);
      clsIdx.push(best);
      coeffsAll.push(data.slice(off+dim-mask_dim,off+dim));
    }
    const keep=nms(boxes,scores);
    ctx.clearRect(0,0,overlay.width,overlay.height);
    for(const i of keep){
      const b=boxes[i];
      ctx.strokeStyle='lime';ctx.lineWidth=2;ctx.strokeRect(b.x1,b.y1,b.x2-b.x1,b.y2-b.y1);
      const mask=buildMask(protoOut.data,coeffsAll[i],mask_h,mask_w);
      drawMask(mask,mask_h,mask_w,b,[0,255,0]);
      const label=`${classes[clsIdx[i]]||clsIdx[i]} ${(scores[i]*100).toFixed(1)}%`;
      ctx.fillStyle='rgba(0,0,0,0.6)';
      ctx.fillRect(b.x1,b.y1-20,ctx.measureText(label).width+6,20);
      ctx.fillStyle='#fff';
      ctx.fillText(label,b.x1+3,b.y1-7);
    }
  }

  async function inferLoop(){
    if(!video||video.readyState<2){rafId=requestAnimationFrame(inferLoop);return;}
    await runInference(video);
    rafId=requestAnimationFrame(inferLoop);
  }

  async function startCamera(){
    stream=await navigator.mediaDevices.getUserMedia({video:{facingMode:'environment'},audio:false});
    video.srcObject=stream;
    video.style.display='block';
    await video.play();
    overlay.width=video.videoWidth;
    overlay.height=video.videoHeight;
    startCam.disabled=true;
    stopBtn.disabled=false;
    status('Камера запущена');
    rafId=requestAnimationFrame(inferLoop);
  }

  function stopAll(){
    if(stream)stream.getTracks().forEach(t=>t.stop());
    if(rafId)cancelAnimationFrame(rafId);
    startCam.disabled=false;
    stopBtn.disabled=true;
    status('Остановлено');
  }

  async function handleFile(e){
    const file=e.target.files[0];
    if(!file)return;
    stopAll();
    const url=URL.createObjectURL(file);
    const isVideo=file.type.startsWith('video');
    status('Обработка...');
    if(isVideo){
      const v=document.createElement('video');
      v.src=url;
      await v.play();
      overlay.width=v.videoWidth;
      overlay.height=v.videoHeight;
      await runInference(v);
