<!doctype html>
<html lang="ru">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>YOLOv11 Segments (WASM) — сегментация объектов</title>
  <style>
    body {
      font-family: system-ui, sans-serif;
      background: #0f172a;
      color: #e2e8f0;
      display: flex;
      flex-direction: column;
      align-items: center;
      margin: 0;
      padding: 1rem;
    }
    h1 { margin-bottom: .5rem }
    video, canvas {
      border-radius: 10px;
      box-shadow: 0 8px 24px rgba(0,0,0,0.6);
    }
    #controls {
      margin-top: 10px;
      display: flex;
      gap: 1rem;
      flex-wrap: wrap;
      justify-content: center;
    }
    button {
      background: #2563eb;
      color: #fff;
      border: none;
      border-radius: 8px;
      padding: .5rem 1rem;
      cursor: pointer;
    }
  </style>
</head>
<body>
  <h1>YOLOv11 + WASM — сегментация объектов</h1>

  <video id="video" autoplay playsinline width="640" height="480"></video>
  <canvas id="overlay" width="640" height="480"></canvas>

  <div id="controls">
    <button id="startBtn">Запустить камеру</button>
    <button id="stopBtn" disabled>Остановить</button>
    <span id="status">Инициализация...</span>
  </div>

  <!-- ONNX Runtime Web -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>

  <script>
  const MODEL_URL = './models/best.onnx';
  const CLASSES_URL = './models/classes.json';
  const MODEL_INPUT = 640;

  const video = document.getElementById('video');
  const overlay = document.getElementById('overlay');
  const ctx = overlay.getContext('2d');
  const startBtn = document.getElementById('startBtn');
  const stopBtn = document.getElementById('stopBtn');
  const statusEl = document.getElementById('status');

  let session = null;
  let stream = null;
  let rafId = null;
  let classes = [];

  function status(t){ statusEl.textContent = t }

  // === Предобработка ===
  function preprocess(video) {
    const tmp = document.createElement('canvas');
    tmp.width = MODEL_INPUT; tmp.height = MODEL_INPUT;
    const tctx = tmp.getContext('2d');
    const vw = video.videoWidth, vh = video.videoHeight;
    const scale = Math.min(MODEL_INPUT/vw, MODEL_INPUT/vh);
    const sw = vw * scale, sh = vh * scale;
    const dx = (MODEL_INPUT - sw)/2, dy = (MODEL_INPUT - sh)/2;
    tctx.fillStyle = "black";
    tctx.fillRect(0,0,MODEL_INPUT,MODEL_INPUT);
    tctx.drawImage(video, 0, 0, vw, vh, dx, dy, sw, sh);
    const img = tctx.getImageData(0,0,MODEL_INPUT,MODEL_INPUT);
    const { data } = img;
    const input = new Float32Array(3 * MODEL_INPUT * MODEL_INPUT);
    for (let i=0; i<MODEL_INPUT*MODEL_INPUT; i++) {
      input[i] = data[i*4]/255;
      input[i+MODEL_INPUT*MODEL_INPUT] = data[i*4+1]/255;
      input[i+2*MODEL_INPUT*MODEL_INPUT] = data[i*4+2]/255;
    }
    return new ort.Tensor('float32', input, [1,3,MODEL_INPUT,MODEL_INPUT]);
  }

  // === Постобработка масок ===
  function sigmoid(x){return 1/(1+Math.exp(-x));}
  function iou(a,b){
    const x1=Math.max(a.x1,b.x1),y1=Math.max(a.y1,b.y1),
          x2=Math.min(a.x2,b.x2),y2=Math.min(a.y2,b.y2);
    const w=Math.max(0,x2-x1),h=Math.max(0,y2-y1);
    const inter=w*h,areaA=(a.x2-a.x1)*(a.y2-a.y1),areaB=(b.x2-b.x1)*(b.y2-b.y1);
    return inter/(areaA+areaB-inter+1e-6);
  }
  function nonMaxSuppression(boxes,scores,thr=0.45){
    const idxs=scores.map((s,i)=>({s,i})).sort((a,b)=>b.s-a.s).map(x=>x.i);
    const keep=[];
    while(idxs.length){
      const i=idxs.shift();
      keep.push(i);
      for(let j=idxs.length-1;j>=0;j--){
        if(iou(boxes[i],boxes[idxs[j]])>thr) idxs.splice(j,1);
      }
    }
    return keep;
  }

  function buildMask(proto, coeffs, mask_h, mask_w) {
    const dim = coeffs.length;
    const mask = new Float32Array(mask_h * mask_w);
    for (let i = 0; i < dim; i++) {
      const channel = proto.slice(i * mask_h * mask_w, (i + 1) * mask_h * mask_w);
      for (let j = 0; j < mask.length; j++) {
        mask[j] += channel[j] * coeffs[i];
      }
    }
    for (let i = 0; i < mask.length; i++) mask[i] = sigmoid(mask[i]);
    return mask;
  }

  function drawMask(mask, mask_h, mask_w, box, color) {
    const img = ctx.createImageData(mask_w, mask_h);
    for (let i = 0; i < mask.length; i++) {
      const v = mask[i] > 0.5 ? 255 : 0;
      img.data[i*4+0] = color[0];
      img.data[i*4+1] = color[1];
      img.data[i*4+2] = color[2];
      img.data[i*4+3] = v;
    }
    const mcanvas = document.createElement('canvas');
    mcanvas.width = mask_w; mcanvas.height = mask_h;
    const mctx = mcanvas.getContext('2d');
    mctx.putImageData(img, 0, 0);
    ctx.globalAlpha = 0.4;
    ctx.drawImage(mcanvas, box.x1, box.y1, box.x2-box.x1, box.y2-box.y1);
    ctx.globalAlpha = 1.0;
  }

  // === Главный цикл инференса ===
  async function inferLoop(){
    if(!video || video.readyState < 2){ rafId = requestAnimationFrame(inferLoop); return; }
    const tensor = preprocess(video);
    const feeds = { [session.inputNames[0]]: tensor };
    try {
      const out = await session.run(feeds);
      const detOut = out[session.outputNames[0]];
      const protoOut = out[session.outputNames[1]]; // для сегментации
      const data = detOut.data;
      const [batch, num, dim] = detOut.dims;
      const mask_dim = protoOut.dims[1];
      const mask_h = protoOut.dims[2];
      const mask_w = protoOut.dims[3];
      const boxes=[],scores=[],clsIdx=[],coeffsAll=[];

      for(let i=0;i<num;i++){
        const off=i*dim;
        const cx=data[off],cy=data[off+1],w=data[off+2],h=data[off+3];
        const conf=data[off+4];
        let bestClass=-1,bestScore=0;
        for(let c=5;c<dim-mask_dim;c++){
          if(data[off+c]>bestScore){bestScore=data[off+c];bestClass=c-5;}
        }
        const score=conf*bestScore;
        if(score<0.4) continue;
        boxes.push({x1:(cx-w/2)*overlay.width,y1:(cy-h/2)*overlay.height,
                    x2:(cx+w/2)*overlay.width,y2:(cy+h/2)*overlay.height});
        scores.push(score);
        clsIdx.push(bestClass);
        coeffsAll.push(data.slice(off+dim-mask_dim,off+dim));
      }
      const keep=nonMaxSuppression(boxes,scores);
      ctx.clearRect(0,0,overlay.width,overlay.height);

      for(const i of keep){
        const b=boxes[i];
        const color=[0,255,0];
        ctx.strokeStyle='lime';
        ctx.lineWidth=2;
        ctx.strokeRect(b.x1,b.y1,b.x2-b.x1,b.y2-b.y1);
        const mask=buildMask(protoOut.data,coeffsAll[i],mask_h,mask_w);
        drawMask(mask,mask_h,mask_w,b,color);
        const label=`${classes[clsIdx[i]]||clsIdx[i]} ${(scores[i]*100).toFixed(1)}%`;
        ctx.fillStyle='rgba(0,0,0,0.6)';
        ctx.fillRect(b.x1,b.y1-20,ctx.measureText(label).width+6,20);
        ctx.fillStyle='#fff';
        ctx.fillText(label,b.x1+3,b.y1-17);
      }
    } catch(e){
      console.error(e);
      status('Ошибка инференса');
    }
    rafId = requestAnimationFrame(inferLoop);
  }

  // === Камера ===
  async function startCamera(){
    try{
      stream=await navigator.mediaDevices.getUserMedia({video:{facingMode:'environment'},audio:false});
      video.srcObject=stream;
      await video.play();
      overlay.width=video.videoWidth;
      overlay.height=video.videoHeight;
      status('Камера запущена');
      startBtn.disabled=true; stopBtn.disabled=false;
      rafId=requestAnimationFrame(inferLoop);
    }catch(e){status('Ошибка камеры'); console.error(e);}
  }
  function stopCamera(){
    if(stream) stream.getTracks().forEach(t=>t.stop());
    if(rafId) cancelAnimationFrame(rafId);
    startBtn.disabled=false; stopBtn.disabled=true;
    status('Остановлено');
  }

  // === Инициализация ===
  async function initOrt(){
    status('Загрузка модели...');
    session = await ort.InferenceSession.create(MODEL_URL, { executionProviders:['wasm'] });
    status('Модель загружена');
  }
  async function loadClasses(){
    try{
      const r=await fetch(CLASSES_URL);
      classes=await r.json();
    }catch{classes=[];}
  }

  (async()=>{
    await loadClasses();
    await initOrt();
    status('Готово — нажмите «Запустить камеру»');
  })();

  startBtn.addEventListener('click', startCamera);
  stopBtn.addEventListener('click', stopCamera);
  window.addEventListener('beforeunload', ()=>{if(stream)stream.getTracks().forEach(t=>t.stop());});
  </script>
</body>
</html>
